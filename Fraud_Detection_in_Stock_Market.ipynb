{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPGziEwdBSx9TgBIH+TPZ4G"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import plotly.express as px\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.cluster import DBSCAN\n","\n","# Load Orders Dataset\n","orders = pd.read_csv(\"/content/Orders.csv\")\n","\n","# Load Trades Dataset with Corrected Column Names\n","trades = pd.read_csv(\"/content/Trades.CSV\")\n","\n","# ✅ Clean Column Names (Fix Spacing & Capitalization Issues)\n","orders.columns = orders.columns.str.strip().str.upper()\n","trades.columns = trades.columns.str.strip().str.upper()\n","\n","# ✅ Ensure 'SCRIP_CODE' Exists in Both Datasets\n","if \"SCRIP_CODE\" not in orders.columns or \"SCRIP_CODE\" not in trades.columns:\n","    raise ValueError(\"SCRIP_CODE column is missing in one of the datasets!\")\n","\n","# ✅ Convert Order and Trade IDs to Strings to Avoid Scientific Notation Issues\n","orders[\"ORDER_ID\"] = orders[\"ORDER_ID\"].astype(str)\n","trades[\"BUY_ORDER_ID\"] = trades[\"BUY_ORDER_ID\"].astype(str)\n","trades[\"SELL_ORDER_ID\"] = trades[\"SELL_ORDER_ID\"].astype(str)\n","\n","# ✅ Convert Date and Time Columns to Proper Format\n","orders[\"ORDER_TIMESTAMP\"] = pd.to_datetime(orders[\"ORDER_DATE\"] + \" \" + orders[\"ORDER_TIME\"], errors=\"coerce\")\n","trades[\"TRADE_TIMESTAMP\"] = pd.to_datetime(trades[\"TRADE_DATE\"] + \" \" + trades[\"TRADE_TIME\"], errors=\"coerce\")\n","\n","# ✅ Selecting Key Features for Clustering\n","features = [\"RATE\", \"QUANTITY\", \"TRADE_RATE\", \"TRADE_QUANTITY\", \"TRADE_VALUE\"]\n","\n","# ✅ Merge Orders and Trades on 'SCRIP_CODE'\n","merged = pd.merge(orders, trades, on=\"SCRIP_CODE\", how=\"inner\")\n","\n","# ✅ Handle Missing Values\n","data = merged[features].dropna()\n","\n","# ✅ Standardizing the Data\n","scaler = StandardScaler()\n","data_scaled = scaler.fit_transform(data)\n","\n","# ✅ Applying DBSCAN\n","dbscan = DBSCAN(eps=1.5, min_samples=10)\n","clusters = dbscan.fit_predict(data_scaled)\n","\n","# ✅ Assign Cluster Labels\n","merged[\"Cluster\"] = clusters\n","\n","# ✅ Identifying Anomalies (Noise Points)\n","anomalies = merged[merged[\"Cluster\"] == -1]\n","\n","# ✅ Visualization - 2D Scatter Plot\n","plt.figure(figsize=(12, 6))\n","sns.scatterplot(data=merged, x=\"TRADE_QUANTITY\", y=\"TRADE_VALUE\", hue=\"Cluster\", palette=\"viridis\", alpha=0.7)\n","plt.title(\"DBSCAN Clustering for Fraud Detection\")\n","plt.xlabel(\"Trade Quantity\")\n","plt.ylabel(\"Trade Value\")\n","plt.legend(title=\"Cluster\")\n","plt.show()\n","\n","# ✅ Interactive 3D Plot\n","fig = px.scatter_3d(merged, x=\"RATE\", y=\"TRADE_QUANTITY\", z=\"TRADE_VALUE\",\n","                     color=merged[\"Cluster\"].astype(str),\n","                     title=\"DBSCAN 3D Visualization\",\n","                     opacity=0.7)\n","fig.show()\n","\n","# ✅ Save Fraudulent Trades\n","anomalies.to_csv(\"Detected_Fraudulent_Trades.csv\", index=False)\n","print(f\"✅ Total Fraudulent Transactions Detected: {len(anomalies)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n1ao_1t9w6UB","outputId":"f4d2aa5c-e8e3-4112-be6e-c65ea3b77cf0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-4-3352c7a5ba59>:29: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  orders[\"ORDER_TIMESTAMP\"] = pd.to_datetime(orders[\"ORDER_DATE\"] + \" \" + orders[\"ORDER_TIME\"], errors=\"coerce\")\n","<ipython-input-4-3352c7a5ba59>:30: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  trades[\"TRADE_TIMESTAMP\"] = pd.to_datetime(trades[\"TRADE_DATE\"] + \" \" + trades[\"TRADE_TIME\"], errors=\"coerce\")\n"]}]}]}